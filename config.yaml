version: '1.0.0'

seed: 42

url: 'https://www.example.com/jobs'
pages: 500


dirs:
  data: 'data'
  notebooks: 'notebooks'
  artifacts: 'artifacts'
  logs: 'logs'

files:
  # Data files (live in data/ directory)
  raw_data: 'raw_df.csv'
  feature_engineered: 'df_feature_engineered.csv'
  preprocessed_train: 'preprocessed_train_df.csv'
  preprocessed_test: 'preprocessed_test_df.csv'
  train_data: 'train_df.csv'
  test_data: 'test_df.csv'
  
  # Preprocessing artifacts (live in artifacts/ directory)
  one_hot_encoder: 'one_hot_encoder.pkl'
  mlb: 'mlb.pkl'
  scaler: 'scaler.pkl'
  
  # Model artifacts (live in artifacts/ directory)
  final_model: 'final_model.pkl'              # trained model
  best_model_name: 'best_model_name.txt'      # name of best model
  selected_features: 'selected_features.pkl'   # selected features list
  best_params: 'best_params.pkl'               # best hyperparameters

  # Evaluation results
  predictions: 'model_predictions.csv'
  evaluation_metrics: 'evaluation_metrics.csv'
  evaluation_report: 'evaluation_report.txt'
  evaluation_plots: 'evaluation_plots.png'
  feature_importance_plot: 'feature_importance_plot.png'

preprocessing:
  # Splitter object
  train_size: 0.8
  random_state: 42
  # Preprocessor object
  transform_target: true
  all_features: ['job_title',
                 'seniority_level',
                 'status',
                 'company',
                 'location',
                 'headquarter',
                 'industry',
                 'ownership',
                 'company_size',
                 'revenue',
                 'skills',
                 'min_salary',
                 'max_salary',
                 'mean_salary']
  columns_to_drop: ['min_salary',  # Not informative
                    'max_salary',  # Not informative
                    'revenue',  # Large number of missing values
                    'company',  # Not informative
                    'job_title',  # High frequency of dominant category
                    ]
  target: ['mean_salary']  # defined so for serving
  # target: 'mean_salary'
  ordinal_features: ['seniority_level']
  numerical_features: ['company_size']
  categorical_features: ['status', 'location',
                         'headquarter', 'industry', 'ownership']

training:
  feature_counts: [5, 10, 15, 20, 30, 40]
  random_state: 42
  cv_splits: 5
  shuffle: True
  scoring: neg_mean_squared_error
  default_model:
    name: "RandomForestRegressor"
    params:
      n_estimators: 100
      random_state: 42
  final_models:
    LinearRegression: {}
    Lasso:
      alpha: 0.1
      random_state: 42
    Ridge:
      alpha: 0.1
      random_state: 42
    RandomForestRegressor:
      n_estimators: 300
      random_state: 42
    GradientBoostingRegressor:
      n_estimators: 300
      random_state: 42
    XGBRegressor:
      n_estimators: 300
      random_state: 42
  rfe_step: 2
  save_flag: True
  logging_flag: True

exporting:
  repo_id: 'your-username/ds-salary'
  api_token: 'your-hf-api-token'

inference:
  feature_selection: True
