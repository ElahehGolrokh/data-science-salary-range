version: '1.0.0'

seed: 42

url: 'https://www.example.com/jobs'
pages: 500


dirs:
  data: 'data'
  notebooks: 'notebooks'
  # preprocessing & modeling objects & files
  artifacts: 'artifacts'

files:
  # all of data files live in data/ directory in this repo
  raw_data: 'raw_df.csv'
  feature_engineered: 'df_feature_engineered.csv'
  preprocessed_train: 'preprocessed_train_df.csv'
  preprocessed_test: 'preprocessed_test_df.csv'
  # training & testing data after split
  train_data: 'train_df.csv'
  test_data: 'test_df.csv'
  # preprocessing objects & files. from here, the files live in artifacts/ in this repo
  one_hot_encoder: 'one_hot_encoder.pkl'
  mlb: 'mlb.pkl'
  scaler: 'scaler.pkl'
  # model artifacts
  model: final_model.pkl
  best_model_name: best_model_name.txt
  feature_selector: final_selected_features.pkl

preprocessing:
  # Splitter object
  train_size: 0.8
  random_state: 42
  # Preprocessor object
  transform_target: true
  all_features: ['job_title',
                 'seniority_level',
                 'status',
                 'company',
                 'location',
                 'headquarter',
                 'industry',
                 'ownership',
                 'company_size',
                 'revenue',
                 'skills',
                 'min_salary',
                 'max_salary',
                 'mean_salary']
  columns_to_drop: ['min_salary',  # Not informative
                    'max_salary',  # Not informative
                    'revenue',  # Large number of missing values
                    'company',  # Not informative
                    'job_title',  # High frequency of dominant category
                    ]
  target: ['mean_salary']
  numerical_features: ['company_size']
  categorical_features: ['seniority_level', 'status', 'location',
                        'headquarter', 'industry', 'ownership']

training:
  feature_counts: [5, 10, 15, 20, 30, 40]
  random_state: 42
  cv_splits: 5
  shuffle: True
  scoring: neg_mean_squared_error
  default_model:
    name: "RandomForest"
    params:
      n_estimators: 100
      random_state: 42
  final_models:
    LinearRegression: {}
    Lasso:
      alpha: 0.1
      random_state: 42
    Ridge:
      alpha: 0.1
      random_state: 42
    RandomForest:
      n_estimators: 300
      random_state: 42
    GradientBoosting:
      n_estimators: 300
      random_state: 42
    XGB:
      n_estimators: 300
      random_state: 42
  rfe_step: 2
  save_flag: True
  logging_flag: True

exporting:
  repo_id: 'your-username/ds-salary'
  api_token: 'your-hf-api-token'

inference:
  feature_selection: true
